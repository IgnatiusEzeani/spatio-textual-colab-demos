{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# demo_1_entity_annotation.ipynb\n\n",
        "_Entity annotation demo with Q↔A-aware testimony segmentation_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "1. [Setup](#setup)\n",
        "2. [Imports](#imports)\n",
        "3. [Data & Quick Demo](#data-demo)\n",
        "4. [Main Tutorial](#main)\n",
        "5. [Tips & Troubleshooting](#tips)\n",
        "6. [Summary](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup  <a id='setup'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running on Colab, install dependencies.\n",
        "# Note: Uncomment as needed.\n",
        "# %pip -q install spacy geonamescache tqdm folium\n",
        "# Optional backends (uncomment where relevant):\n",
        "# %pip -q install transformers torch openai\n\n",
        "# Download at least one spaCy model\n",
        "# !python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports  <a id='imports'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spatio_textual.utils import load_spacy_model, Annotator, save_annotations, load_annotations\n",
        "from spatio_textual.qa import segment_testimony\n",
        "from spatio_textual.sentiment import SentimentAnalyzer\n",
        "from spatio_textual.emotion import EmotionAnalyzer\n",
        "from spatio_textual.analysis import analyze_records\n",
        "from spatio_textual.viz import to_geojson, make_map_geojson, build_cooccurrence\n\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data & Quick Demo  <a id='data-demo'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"Anne Frank was taken from Amsterdam to Auschwitz.\"\n\n",
        "nlp = load_spacy_model(\"en_core_web_sm\")\n",
        "annotator = Annotator(nlp)\n\n",
        "# Basic annotation (entities + optional verbs)\n",
        "rec = annotator.annotate(text, include_verbs=True)\n",
        "rec.update({\"fileId\":\"example\",\"segId\":1,\"segCount\":1,\"text\":text})\n",
        "rec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Tutorial  <a id='main'></a>\n\n",
        "### 1) Annotate a list of segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "segments = [text, text]\n",
        "recs = annotator.annotate_texts(segments, file_id=\"sample\", include_text=True, include_verbs=True)\n",
        "pd.DataFrame([{\"segId\":r[\"segId\"],\"entities\":len(r[\"entities\"]), \"verbs\":len(r[\"verb_data\"])} for r in recs])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Q↔A‑aware segmentation of testimony with `qa.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw = f\"Q: {text}\\nA: I was separated from my family in Amsterdam.\"\n",
        "qa_segments = segment_testimony(raw, nlp=nlp)\n",
        "qa_segments[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Annotate QA segments\n",
        "qa_texts = [s.text for s in qa_segments]\n",
        "qa_recs = annotator.annotate_texts(qa_texts, file_id=\"testimony\", include_text=True)\n",
        "# Attach QA metadata\n",
        "for r, s in zip(qa_recs, qa_segments):\n",
        "    r.update({\n",
        "        \"role\": s.role,\n",
        "        \"turnId\": s.turn_id,\n",
        "        \"isQuestion\": s.is_question,\n",
        "        \"isAnswer\": s.is_answer,\n",
        "        \"qaPairId\": s.qa_pair_id,\n",
        "    })\n",
        "qa_df = pd.DataFrame([{k:r.get(k) for k in [\"segId\",\"role\",\"isQuestion\",\"isAnswer\",\"text\"]} for r in qa_recs])\n",
        "qa_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Save & reload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_annotations(qa_recs, \"entity_demo.jsonl\")\n",
        "df = load_annotations(\"entity_demo.jsonl\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips & Troubleshooting  <a id='tips'></a>\n",
        "- If a spaCy model is missing, run the download cell in *Setup*.\n",
        "- Keep `--resources-dir` consistent if you use custom pattern lists.\n",
        "- For very large corpora, prefer JSONL and use chunked processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary  <a id='summary'></a>\n",
        "We covered single-text and list annotation, plus Q↔A testimony segmentation with sentence-safe splits and metadata."
      ]
    }
  ],
  "metadata": {
    "colab": {"name": "demo_1_entity_annotation.ipynb", "provenance": []},
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "pygments_lexer": "ipython3"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
