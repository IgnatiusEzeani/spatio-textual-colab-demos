{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/spatio-textual-colab-demos/blob/main/demo_2_sentiment_emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHEI31rJWhul"
      },
      "source": [
        "# Sentiment and Emotion with `spatio-textual`\n",
        "---\n",
        "\n"
      ],
      "id": "NHEI31rJWhul"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction 👋\n",
        "\n",
        "This notebook explores the sentiment and emotion classification capabilities of the `spatio-textual` package.\n",
        "\n",
        "We will demonstrate how to use rule-based, HuggingFace, and LLM-based approaches to analyze the sentiment and emotion expressed in text. The notebook builds upon the entity annotation concepts introduced in a previous demo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_y96aCFLV6qs"
      },
      "id": "_y96aCFLV6qs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98ebb548"
      },
      "source": [
        "### Downloads ⬇️\n",
        "As earlier, download the [spaCy](https://spacy.io/)'s NLP model, `en_core_web_trf`, and install the `spatio-textual` package."
      ],
      "id": "98ebb548"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKJhFm_eWhun"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_trf -q\n",
        "!pip install -q git+https://github.com/SpaceTimeNarratives/spatio-textual.git"
      ],
      "id": "GKJhFm_eWhun"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a553ef9e"
      },
      "source": [
        "### Imports 📥\n",
        "Let's import the necessary tools: `load_spacy_model` and `Annotator` from `spatio_textual.utils`.\n",
        "\n",
        "We also need `pandas` for working with data frames."
      ],
      "id": "a553ef9e"
    },
    {
      "cell_type": "code",
      "source": [
        "import spatio_textual\n",
        "from spatio_textual.utils import load_spacy_model, Annotator\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8sYknbn8LGZQ"
      },
      "id": "8sYknbn8LGZQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d674a18f"
      },
      "source": [
        "### Annotating entities 📝\n",
        "\n",
        "As in Demo 1, we need the `spaCy` model and the `Annotator` module for the spatial entity annotations."
      ],
      "id": "d674a18f"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Use `spaCy` nlp model to instantiate `Annotator`\n",
        "nlp = load_spacy_model(\"en_core_web_trf\")\n",
        "ann = Annotator(nlp)"
      ],
      "metadata": {
        "id": "TxE6cFH9QLxN"
      },
      "id": "TxE6cFH9QLxN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Consider these example texts\n",
        "texts = [\n",
        "    \"I felt safe and relieved when we reached the farmhouse.\",\n",
        "    \"We were afraid, hungry, and cold during the march.\",\n",
        "    \"They asked us questions.\",\n",
        "]"
      ],
      "metadata": {
        "id": "dRfsW3optxOK"
      },
      "id": "dRfsW3optxOK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### We start by annotating the `entities` (see [Demo 1](https://github.com/SpaceTimeNarratives/spatio-textual-colab-demos/blob/main/demo_1_entity_annotation.ipynb))\n",
        "entities = ann.annotate_texts(\n",
        "    texts,\n",
        "    file_id=\"sent_demo\",  # Use what is relevant for your work\n",
        "    include_text=True,    # Let's you include the text in the result\n",
        "    include_verbs=True)   # Let's you extract verbs\n",
        "entities"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pHaQtCmbsVgm"
      },
      "id": "pHaQtCmbsVgm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\"]} for row in entities])"
      ],
      "metadata": {
        "id": "ITpr6Q9RvhnS"
      },
      "id": "ITpr6Q9RvhnS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd276598"
      },
      "source": [
        "* * *\n",
        "## Adding Sentiment ✅❌"
      ],
      "id": "fd276598"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need a module called `SentimentAnalyzer` from `spatio_textual.sentiment`. It's backend supports three distinct approaches to assigning sentiments to text:\n",
        "- `rule`: uses a **rule-based** method with sentiment lexicon to estimate a sentiment score for the text\n",
        "- `hf`: uses **HuggingFace** models via its `sentiment-analysis` pipeline.   \n",
        "- `llm`: uses large language models, **LLMs** and supports some of the common providers and models:\n",
        "  - providers: `openai`, `anthropic`, `google`, `groq`, `xai`, `ollama`\n",
        "  - models: `gpt-4o-mini`, `claude-3-5-sonnet-20240620`, `gemini-1.5-pro`, `llama3:8b`"
      ],
      "metadata": {
        "id": "hMEi43IDvm93"
      },
      "id": "hMEi43IDvm93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04683653"
      },
      "source": [
        "### 1. Rule-based Sentiment Analysis 📊"
      ],
      "id": "04683653"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This approach is quite basic. The key steps include:\n",
        "1. Split the text into words (lowercase; strip punctuation).\n",
        "2. Count how many words are in a **positive** lexicon and how many are in a **negative** lexicon.\n",
        "    * `pos = #positive words in text`\n",
        "    * `neg = #negative words in text`\n",
        "\n",
        "3. Compute a raw balance:\n",
        "    * `raw = pos − neg`.\n",
        "4. Convert that raw number into a bounded score in **\\[−1, 1]** using a smooth squash (`tanh`).\n",
        "\n",
        "$$\n",
        "\\text{score} = \\tanh\\!\\left(\\frac{\\text{raw}}{3}\\right) \\in [-1, 1]\n",
        "$$\n",
        "\n",
        "\n",
        "5. Assign a label based on the score:\n",
        "$$\n",
        "\\text{label} =\n",
        "\\begin{cases}\n",
        "\\text{positive} & \\text{if } \\text{score} > 0.15 \\\\\n",
        "\\text{negative} & \\text{if } \\text{score} < -0.15 \\\\\n",
        "\\text{neutral} & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "**Quick examples:**\n",
        "\n",
        "* 2 positive words, 1 negative: $\\text{raw}=1\\Rightarrow\\text{score}=\\tanh(1/3)\\approx 0.32\\Rightarrow$ **positive**.\n",
        "* 1 positive, 1 negative: $\\text{raw}=0\\Rightarrow\\text{score}=0\\Rightarrow$ **neutral**.\n",
        "* 0 positive, 3 negative: $\\text{raw}=-3\\Rightarrow\\text{score}=\\tanh(-1)\\approx -0.76\\Rightarrow$ **negative**.\n"
      ],
      "metadata": {
        "id": "LumR3EG4t9jH"
      },
      "id": "LumR3EG4t9jH"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### So let's import `SentimentAnalyzer`...\n",
        "from spatio_textual.sentiment import SentimentAnalyzer"
      ],
      "metadata": {
        "id": "5ghuQfxlu5aM"
      },
      "id": "5ghuQfxlu5aM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### ... and then classify the example...\n",
        "sa = SentimentAnalyzer(\"rule\")\n",
        "sentiment_scores = sa.predict(texts)\n",
        "sentiment_scores"
      ],
      "metadata": {
        "id": "xNuH1cnf2eKQ"
      },
      "id": "xNuH1cnf2eKQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### ...and combine it with `entities`.\n",
        "results = entities\n",
        "for r, p in zip(results, sentiment_scores):\n",
        "    r.update({\"sentiment_label\": p[\"label\"], \"sentiment_score\": p[\"score\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"sentiment_label\",\"sentiment_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "jCNBmK8s7MHA"
      },
      "id": "jCNBmK8s7MHA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d948814"
      },
      "source": [
        "### 2. Sentiment Analysis with HuggingFace 🤗\n",
        "\n",
        "To use the `HuggingFace` pipeline for sentiment analysis at the backend, we simply pass the `hf` parameter while initialising the `SentimentAnalyzer` object."
      ],
      "id": "2d948814"
    },
    {
      "cell_type": "code",
      "source": [
        "sa = SentimentAnalyzer(\"hf\")"
      ],
      "metadata": {
        "id": "BCRhuJHfAlUw"
      },
      "id": "BCRhuJHfAlUw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default model is [CardiffNLP](https://cardiffnlp.github.io/)'s [twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) but you can pass any other model on HuggingFace e.g.\n",
        "\n",
        "\n",
        ">```python\n",
        ">sa = SentimentAnalyzer(\"hf\", model_name=\"siebert/sentiment-roberta-large-english\")\n",
        ">```"
      ],
      "metadata": {
        "id": "ieI7LmY2fRaZ"
      },
      "id": "ieI7LmY2fRaZ"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    hf_sentiment_scores = sa.predict(texts)\n",
        "\n",
        "hf_sentiment_scores"
      ],
      "metadata": {
        "id": "KickdAR4GJ8z"
      },
      "id": "KickdAR4GJ8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### As earlier, we can combine the results with the extracted `entities`.\n",
        "results = entities\n",
        "for r, p in zip(results, hf_sentiment_scores):\n",
        "    r.update({\"hf_sentiment_label\": p[\"label\"], \"hf_sentiment_score\": p[\"score\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"hf_sentiment_label\",\"hf_sentiment_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "LAFgJrb0gM2h"
      },
      "id": "LAFgJrb0gM2h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Observe that unlike the rule-based scores that are signed to indicate positive and negative, HuggingFace (transformer) sentiment scoring basically shows probability values indicating how 'confident' the model is in the decision.\n",
        "\n",
        "The `spatio-textual` package allows us to convert the scores to signed values if required by setting the `include_signed` parameter to `True`."
      ],
      "metadata": {
        "id": "X_-Fdv_swg7x"
      },
      "id": "X_-Fdv_swg7x"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### So let's try that...\n",
        "hf_sentiment_scores = sa.predict(texts, include_signed=True)\n",
        "hf_sentiment_scores"
      ],
      "metadata": {
        "id": "TCffK8Ta-kd3"
      },
      "id": "TCffK8Ta-kd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### ...and of course combine it with `entities`.\n",
        "results = entities\n",
        "for r, p in zip(results, hf_sentiment_scores):\n",
        "    r.update({\"hf_sentiment_label\": p[\"label\"], \"hf_sentiment_score\": p[\"score\"],\n",
        "              \"hf_signed_score\": p[\"signed\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"hf_sentiment_label\",\n",
        "    \"hf_sentiment_score\", \"hf_signed_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "RlvV4gNxAXnG"
      },
      "id": "RlvV4gNxAXnG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e7ede77"
      },
      "source": [
        "### 3. LLM-based Sentiment Analysis 🤖"
      ],
      "id": "9e7ede77"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`spatio_textual.sentiment` has a built in LLM support for theses providers and their models: **openai**: `gpt-4o-mini`, **anthropic**: `claude-3-5-sonnet-20240620`, **google**: `gemini-1.5-pro`, **groq**: `llama3-70b-8192` (or mixtral, etc), **xai**: `grok-beta` (use `base_url=https://api.x.ai, OPENAI-compatible`), **ollama**: `llama3:8b` (local)\n"
      ],
      "metadata": {
        "id": "12qvRBOzfs54"
      },
      "id": "12qvRBOzfs54"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need the `LLMRouter` from the `spatio_textual.llm` module to define the LLM provider (e.g `openai`), the specific model (e.g. `gpt-4o-mini`) as well as API key and other parameters.\n",
        "> You can store your API keys on Colab for easy access or paste it when prompted in the is demo"
      ],
      "metadata": {
        "id": "VAqIL0ztLK_F"
      },
      "id": "VAqIL0ztLK_F"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### So let's import `LLMRouter` and set the API key.\n",
        "from spatio_textual.llm import LLMRouter\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "  api_key = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "  api_key = input('API KEY: ')"
      ],
      "metadata": {
        "id": "F2rt2apk7SPJ"
      },
      "id": "F2rt2apk7SPJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### We can now set up the router and instantiate `SentimentAnalyzer` with `llm` for the backend.\n",
        "router = LLMRouter(provider=\"openai\", model=\"gpt-4o-mini\",\n",
        "    api_key= api_key, # else OPENAI_API_KEY / ANTHROPIC_API_KEY / GOOGLE_API_KEY / GROQ_API_KEY\n",
        "    # base_url=\"https://api.x.ai\",  # for OpenAI-compatible endpoints like xAI/Together\n",
        "    temperature=0.0,\n",
        "    max_tokens=64,\n",
        ")\n",
        "sa = SentimentAnalyzer(backend=\"llm\", llm_fn=router.sentiment)"
      ],
      "metadata": {
        "id": "_1UfbK7avhYb"
      },
      "id": "_1UfbK7avhYb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Now we are ready to predict texts.\n",
        "llm__sentiment_scores = sa.predict(texts)\n",
        "llm__sentiment_scores"
      ],
      "metadata": {
        "id": "sYNG8JONCHTR"
      },
      "id": "sYNG8JONCHTR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Oh 🤔, we probably need the signed scores as well.\n",
        "llm__sentiment_scores = sa.predict(texts, include_signed=True)\n",
        "llm__sentiment_scores"
      ],
      "metadata": {
        "id": "_b8UQyZkQQj4"
      },
      "id": "_b8UQyZkQQj4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Combining it with `entities`...\n",
        "results = entities\n",
        "for r, p in zip(results, llm__sentiment_scores):\n",
        "    r.update({\"llm_sentiment_label\": p[\"label\"], \"llm_sentiment_score\": p[\"score\"],\n",
        "              \"llm_signed_score\": p[\"signed\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"llm_sentiment_label\",\n",
        "    \"llm_sentiment_score\", \"llm_signed_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "cVHyk_K0Rcay"
      },
      "id": "cVHyk_K0Rcay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* * *\n",
        "## Adding Emotion 😃🙂❤️😠😱😡"
      ],
      "metadata": {
        "id": "_9x7rQXh5WHH"
      },
      "id": "_9x7rQXh5WHH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fef32b76"
      },
      "source": [
        "### Expanding `texts` with Emotion Classes 🎭"
      ],
      "id": "fef32b76"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Let's expanded `texts` a bit to reflect other emotion classes\n",
        "texts = [\n",
        "    # JOY (positive valence)\n",
        "    \"I felt safe and relieved when we reached the farmhouse.\",\n",
        "    \"We were reunited with my sister and welcomed inside.\",\n",
        "\n",
        "    # SURPRISE (slightly positive/neutral valence)\n",
        "    \"Suddenly, the guards announced a change we did not expect.\",\n",
        "    \"To my surprise, the train stopped before dawn.\",\n",
        "\n",
        "    # SADNESS (negative valence)\n",
        "    \"I cried for days after the loss of my friend.\",\n",
        "    \"We mourned in silence, thinking about those who were gone.\",\n",
        "\n",
        "    # FEAR (negative valence)\n",
        "    \"We were afraid, hungry, and cold during the march.\",\n",
        "    \"I was terrified when the sirens sounded across the camp.\",\n",
        "\n",
        "    # ANGER (negative valence)\n",
        "    \"I was furious at the cruelty we faced.\",\n",
        "    \"He spoke with rage about the injustice they suffered.\",\n",
        "\n",
        "    # DISGUST (negative valence)\n",
        "    \"We were disgusted by the filth in the barracks.\",\n",
        "    \"The stench made us nauseated and we looked away.\",\n",
        "\n",
        "    # NEUTRAL (baseline)\n",
        "    \"They asked us questions.\",\n",
        "    \"We walked along the road and waited in line.\",\n",
        "]"
      ],
      "metadata": {
        "id": "wzoH4-3DxRdF",
        "cellView": "form"
      },
      "id": "wzoH4-3DxRdF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### As in the sentiment example, we want to annotate the `entities` in `texts`\n",
        "entities = ann.annotate_texts(\n",
        "    texts,\n",
        "    include_text=True,    # Let's you include the text in the result\n",
        "    include_verbs=True)   # Let's you extract verbs\n",
        "entities\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\"]} for row in entities])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZdxtsE8xA383",
        "cellView": "form"
      },
      "id": "ZdxtsE8xA383",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's label each text with one of the emotion classes.\n",
        "\n",
        "We will start by importing the `EmotionAnalyzer` from `spatio_textual`'s `emotion` module."
      ],
      "metadata": {
        "id": "OE4-lg06CmzR"
      },
      "id": "OE4-lg06CmzR"
    },
    {
      "cell_type": "code",
      "source": [
        "from spatio_textual.emotion import EmotionAnalyzer"
      ],
      "metadata": {
        "id": "ZgMyt7r9txrM"
      },
      "id": "ZgMyt7r9txrM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba739eca"
      },
      "source": [
        "### 1. Rule-based Emotion Analysis 📊"
      ],
      "id": "ba739eca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **How it works**\n",
        "1. **Tokenize** the text into lowercase words (strip punctuation).\n",
        "2. **Count matches** against each emotion lexicon: `joy`, `surprise`, `sadness`, `fear`, `anger`, `disgust`.\n",
        "   A `neutral` bucket is kept as baseline (no counts).\n",
        "3. **Convert counts to probabilities** with a softmax. If no matches at all, set `neutral = 1`.\n",
        "4. **Pick the label** as the emotion with the highest probability; the **score** is that top probability.\n",
        "5. Optionally compute a **valence** (signed score in $[-1,1]$) by weighting the distribution with fixed positivity/negativity weights.\n",
        "\n",
        "---\n",
        "\n",
        "**Notation:**\n",
        "\n",
        "Let the emotion set be\n",
        "$\\mathcal{E}=\\{\\text{neutral},\\ \\text{joy},\\ \\text{surprise},\\ \\text{sadness},\\ \\text{fear},\\ \\text{anger},\\ \\text{disgust}\\}$\n",
        "\n",
        "**Counts (per emotion $e$)**\n",
        "$c_e=\\#\\{\\text{tokens matching lexicon for } e\\},\\quad c_{\\text{neutral}}=0.$\n",
        "\n",
        "**Distribution $d_e$ (probabilities)**\n",
        "* If $\\sum_{e\\neq \\text{neutral}} c_e = 0$:\n",
        "  $d_{\\text{neutral}}=1,\\quad d_{e}=0\\ \\text{for } e\\neq \\text{neutral}.$\n",
        "* Else (softmax over counts):\n",
        "  $d_e=\\frac{\\exp(c_e)}{\\sum\\limits_{e'\\in\\mathcal{E}}\\exp(c_{e'})}.$\n",
        "\n",
        "**Label & confidence**\n",
        "\n",
        "$text{label}=\\arg\\max_{e\\in\\mathcal{E}} d_e,\n",
        "\\text{score}=\\max_{e\\in\\mathcal{E}} d_e$\n",
        "\n",
        "---\n",
        "\n",
        "**Optional: Valence (signed score in $([-1,1])$)**\n",
        "\n",
        "Choose fixed weights, $w(e)$: $[w(\\text{neutral})=0, w(\\text{joy})=1, w(\\text{surprise})=0.2, w(\\text{sadness})=-1, w(\\text{fear})=-0.8, w(\\text{anger})=-0.7, w(\\text{disgust})=-0.7]$\n",
        "\n",
        "Then\n",
        "$[\\text{signed}=\\sum_{e\\in\\mathcal{E}} d_e\\,w(e)\\ \\in [-1,1]]$\n",
        "(*Clip to \\([-1,1]\\) if rounding pushes you out of range.*)"
      ],
      "metadata": {
        "id": "hZcx82NJQLBQ"
      },
      "id": "hZcx82NJQLBQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Rule backend with valence and distribution\n",
        "emo = EmotionAnalyzer(backend=\"rule\")\n",
        "emotion_scores = emo.predict(texts, include_signed=True)"
      ],
      "metadata": {
        "id": "ONBd56gbsSOm"
      },
      "id": "ONBd56gbsSOm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Annotate `entities` and add emotion scores...\n",
        "results = entities\n",
        "for r, p in zip(results, emotion_scores):\n",
        "    r.update({\"emotion_label\": p[\"label\"], \"emotion_score\": p[\"score\"],\n",
        "              \"emotion_score\": p[\"signed\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"emotion_label\",\n",
        "    \"emotion_score\", \"emotion_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "VcciCoTC5rAe",
        "collapsed": true
      },
      "id": "VcciCoTC5rAe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81d18551"
      },
      "source": [
        "### 2. Emotion Analysis with HuggingFace 🤗"
      ],
      "id": "81d18551"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) HF backend (pip install transformers), full distribution + valence\n",
        "emo_hf = EmotionAnalyzer(backend=\"hf\", model_name=\"SamLowe/roberta-base-go_emotions\")\n",
        "emotion_scores_hf = emo_hf.predict(texts, include_distribution=True, include_signed=True)"
      ],
      "metadata": {
        "id": "N0USMOGiFMqB"
      },
      "id": "N0USMOGiFMqB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Combine emotion scores with annotated `entities` ...\n",
        "results = entities\n",
        "for r, p in zip(results, emotion_scores_hf):\n",
        "    r.update({\"emotion_label\": p[\"label\"], \"emotion_score\": p[\"score\"],\n",
        "              \"emotion_score\": p[\"signed\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"emotion_label\",\n",
        "    \"emotion_score\", \"emotion_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "EjkMBPBONSDG"
      },
      "id": "EjkMBPBONSDG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90da7cb"
      },
      "source": [
        "### 3. LLM-Based Emotion Analysis 🤖"
      ],
      "id": "e90da7cb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Setting up for the LLM emotion classifier\n",
        "from spatio_textual.llm import LLMRouter\n",
        "router = LLMRouter(provider=\"openai\", model=\"gpt-4o-mini\", api_key=userdata.get('OPENAI_API_KEY'))\n",
        "emo_llm = EmotionAnalyzer(backend=\"llm\", llm_fn=router.emotion)  # router must implement .emotion(texts)"
      ],
      "metadata": {
        "id": "JnXM-IN4RzCc"
      },
      "id": "JnXM-IN4RzCc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Emotion prediction with LLM\n",
        "emo_llm_score = emo_llm.predict(texts, include_distribution=True, include_signed=True)"
      ],
      "metadata": {
        "id": "aYbfNjlWXy97"
      },
      "id": "aYbfNjlWXy97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Again, let's combine LLM emotion scores with annotated `entities` ...\n",
        "results = entities\n",
        "for r, p in zip(results, emotion_scores_hf):\n",
        "    r.update({\"emotion_label\": p[\"label\"], \"emotion_score\": p[\"score\"],\n",
        "              \"emotion_score\": p[\"signed\"]})\n",
        "\n",
        "pd.DataFrame([{k:row.get(k) for k in [\n",
        "    \"segId\",\"text\",\"entities\",\"verb_data\",\"emotion_label\",\n",
        "    \"emotion_score\", \"emotion_score\"\n",
        "    ]} for row in results])"
      ],
      "metadata": {
        "id": "9b14P-jjReu0"
      },
      "id": "9b14P-jjReu0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6cbfba0"
      },
      "source": [
        "* * *\n",
        "## Putting it altogether ✨"
      ],
      "id": "b6cbfba0"
    },
    {
      "cell_type": "code",
      "source": [
        "from spatio_textual.sentiment import SentimentAnalyzer\n",
        "from spatio_textual.emotion import EmotionAnalyzer\n",
        "from spatio_textual.llm import LLMRouter\n",
        "\n",
        "texts = [\n",
        "    \"I felt safe and relieved when we reached the farmhouse.\",\n",
        "    \"We were afraid, hungry, and cold during the march.\",\n",
        "    \"They asked us questions.\"\n",
        "]\n",
        "\n",
        "# Rule (offline)\n",
        "print(SentimentAnalyzer().predict(texts, include_signed=True))\n",
        "print(EmotionAnalyzer().predict(texts, include_distribution=True, include_signed=True))\n",
        "\n",
        "# HF (pip install transformers)\n",
        "sa_hf = SentimentAnalyzer(backend=\"hf\")\n",
        "print(sa_hf.predict(texts, include_signed=True))\n",
        "ea_hf = EmotionAnalyzer(backend=\"hf\")\n",
        "print(ea_hf.predict(texts, include_distribution=True, include_signed=True))\n",
        "\n",
        "# LLM (set env: LLM_PROVIDER=openai, LLM_MODEL=gpt-4o-mini, OPENAI_API_KEY=...)\n",
        "router = LLMRouter(provider=\"openai\", model=\"gpt-4o-mini\", api_key=userdata.get('OPENAI_API_KEY'))\n",
        "sa_llm = SentimentAnalyzer(backend=\"llm\", llm_fn=router)\n",
        "ea_llm = EmotionAnalyzer(backend=\"llm\", llm_fn=router)\n",
        "print(sa_llm.predict(texts, include_signed=True))\n",
        "print(ea_llm.predict(texts, include_distribution=True, include_signed=True))"
      ],
      "metadata": {
        "id": "9cXa4Y289mnt"
      },
      "id": "9cXa4Y289mnt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "968fad2f"
      },
      "source": [
        "# Conclusion ✅\n",
        "\n",
        "In this notebook, we explored different methods for classifying sentiment and emotion using the `spatio-textual` package. We saw how to apply rule-based, HuggingFace, and LLM-based approaches and how to integrate the results with annotated entities.\n",
        "\n",
        "In the next notebooks, we will continue our exploration of `spatio-textual` by demonstrating how to extract events and journeys from text, and how to perform further analysis on the extracted entities and emotions. Stay tuned for more exciting features! 🚀"
      ],
      "id": "968fad2f"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "NVn4p9HqZimN",
        "7PMJR_HS7acT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}