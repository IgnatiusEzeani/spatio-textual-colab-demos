{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/spatio-textual-colab-demos/blob/main/demo_2_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8RgsGkcWRxf"
      },
      "source": [
        "# demo_2_sentiment.ipynb\n",
        "\n",
        "_Sentiment classification (rule backend) + hooks for LLM/HF_\n"
      ],
      "id": "X8RgsGkcWRxf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfrXv7_pWRxg"
      },
      "source": [
        "## Table of Contents\n",
        "1. [Setup](#setup)\n",
        "2. [Imports](#imports)\n",
        "3. [Data & Quick Demo](#data-demo)\n",
        "4. [Main Tutorial](#main)\n",
        "5. [Tips & Troubleshooting](#tips)\n",
        "6. [Summary](#summary)\n"
      ],
      "id": "zfrXv7_pWRxg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTkVaF1iWRxh"
      },
      "source": [
        "## Setup  <a id='setup'></a>"
      ],
      "id": "sTkVaF1iWRxh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il8nGrasWRxh"
      },
      "outputs": [],
      "source": [
        "# %pip -q install spacy geonamescache tqdm\n",
        "# %pip -q install transformers torch  # optional\n",
        "# !python -m spacy download en_core_web_sm\n"
      ],
      "id": "Il8nGrasWRxh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PJN6pEyWRxi"
      },
      "source": [
        "## Imports  <a id='imports'></a>"
      ],
      "id": "4PJN6pEyWRxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9v-YstlWRxi"
      },
      "outputs": [],
      "source": [
        "from spatio_textual.sentiment import SentimentAnalyzer\n",
        "from spatio_textual.utils import load_spacy_model, Annotator\n",
        "import pandas as pd\n"
      ],
      "id": "C9v-YstlWRxi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW-QoUnGWRxj"
      },
      "source": [
        "## Data & Quick Demo  <a id='data-demo'></a>"
      ],
      "id": "BW-QoUnGWRxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyx-S8USWRxj"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"I felt safe and relieved when we reached the farmhouse.\",\n",
        "    \"We were afraid, hungry, and cold during the march.\",\n",
        "    \"They asked us questions.\",\n",
        "]\n",
        "sa = SentimentAnalyzer(\"rule\")\n",
        "sa.predict(texts)\n"
      ],
      "id": "Tyx-S8USWRxj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1YBshUkWRxk"
      },
      "source": [
        "## Main Tutorial  <a id='main'></a>\n",
        "### 1) Annotate + attach sentiment"
      ],
      "id": "f1YBshUkWRxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWxbGAkJWRxk"
      },
      "outputs": [],
      "source": [
        "nlp = load_spacy_model(\"en_core_web_sm\")\n",
        "ann = Annotator(nlp)\n",
        "recs = ann.annotate_texts(texts, file_id=\"sent_demo\", include_text=True)\n",
        "preds = sa.predict([r[\"text\"] for r in recs])\n",
        "for r, p in zip(recs, preds):\n",
        "    r.update({\"sentiment_label\": p[\"label\"], \"sentiment_score\": p[\"score\"]})\n",
        "pd.DataFrame([{k:r.get(k) for k in [\"segId\",\"text\",\"sentiment_label\",\"sentiment_score\"]} for r in recs])\n"
      ],
      "id": "MWxbGAkJWRxk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K4G9S0hWRxk"
      },
      "source": [
        "### 2) Hooking up an HF pipeline (example)"
      ],
      "id": "0K4G9S0hWRxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdAopQ6xWRxk"
      },
      "outputs": [],
      "source": [
        "# from transformers import pipeline\n",
        "# hf = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "# hf(texts)\n"
      ],
      "id": "vdAopQ6xWRxk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOiznz_nWRxk"
      },
      "source": [
        "## Tips & Troubleshooting  <a id='tips'></a>\n",
        "- Rule backend is offline and immediate but simplistic; HF/LLM provide richer signals.\n",
        "- Keep inputs as short segments for better classifier performance.\n"
      ],
      "id": "eOiznz_nWRxk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcLC0GxwWRxl"
      },
      "source": [
        "## Summary  <a id='summary'></a>\n",
        "You ran sentiment classification with the rule backend and saw how to plug an HF pipeline.\n"
      ],
      "id": "PcLC0GxwWRxl"
    }
  ],
  "metadata": {
    "colab": {
      "name": "demo_2_sentiment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}