{
  "cells": [
    {"cell_type":"markdown","metadata":{},"source":["# demo_2_sentiment.ipynb\n\n","_Sentiment classification (rule backend) + hooks for LLM/HF_\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Table of Contents\n","1. [Setup](#setup)\n","2. [Imports](#imports)\n","3. [Data & Quick Demo](#data-demo)\n","4. [Main Tutorial](#main)\n","5. [Tips & Troubleshooting](#tips)\n","6. [Summary](#summary)\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Setup  <a id='setup'></a>"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %pip -q install spacy geonamescache tqdm\n","# %pip -q install transformers torch  # optional\n","# !python -m spacy download en_core_web_sm\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Imports  <a id='imports'></a>"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from spatio_textual.sentiment import SentimentAnalyzer\n","from spatio_textual.utils import load_spacy_model, Annotator\n","import pandas as pd\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Data & Quick Demo  <a id='data-demo'></a>"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["texts = [\n","    \"I felt safe and relieved when we reached the farmhouse.\",\n","    \"We were afraid, hungry, and cold during the march.\",\n","    \"They asked us questions.\",\n","]\n","sa = SentimentAnalyzer(\"rule\")\n","sa.predict(texts)\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Main Tutorial  <a id='main'></a>\n","### 1) Annotate + attach sentiment"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nlp = load_spacy_model(\"en_core_web_sm\")\n","ann = Annotator(nlp)\n","recs = ann.annotate_texts(texts, file_id=\"sent_demo\", include_text=True)\n","preds = sa.predict([r[\"text\"] for r in recs])\n","for r, p in zip(recs, preds):\n","    r.update({\"sentiment_label\": p[\"label\"], \"sentiment_score\": p[\"score\"]})\n","pd.DataFrame([{k:r.get(k) for k in [\"segId\",\"text\",\"sentiment_label\",\"sentiment_score\"]} for r in recs])\n"]},
    {"cell_type":"markdown","metadata":{},"source":["### 2) Hooking up an HF pipeline (example)"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from transformers import pipeline\n","# hf = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n","# hf(texts)\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Tips & Troubleshooting  <a id='tips'></a>\n","- Rule backend is offline and immediate but simplistic; HF/LLM provide richer signals.\n","- Keep inputs as short segments for better classifier performance.\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Summary  <a id='summary'></a>\n","You ran sentiment classification with the rule backend and saw how to plug an HF pipeline.\n"]}
  ],
  "metadata": {"colab": {"name": "demo_2_sentiment.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}},
  "nbformat": 4,
  "nbformat_minor": 5
}
